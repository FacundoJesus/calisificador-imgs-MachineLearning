# -*- coding: utf-8 -*-
"""Transferencia de Aprendizaje

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19mF87gr__Ui3At8recmoWOVnNU34cc2v
"""

# Transferencia de aprendizaje / Transfer Learning

# Crear nuestro propio conjunto de datos
!unzip rostros_hombres/rostros_hombres.zip -d rostros_hombres

!unzip rostros_mujeres/rostros_mujeres.zip -d rostros_mujeres

!rm -rf rostros_hombres/rostros_hombres.zip
!rm -rf rostros_mujeres/rostros_mujeres.zip

# Crear set de datos (ya no en memoria)
!mkdir dataset
!cp -r rostros_hombres dataset/rostros_hombres # De la carpeta rostros_hombres a la carpeta dataset/rostros_hombres
!cp -r rostros_mujeres dataset/rostros_mujeres # Idem

# Aumento de datos
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

# Crear el dataset generador
datagen = ImageDataGenerator(
    rescale = 1. / 255, # Cambiar las imágenes para que sean normalizadas dividiéndolas en 255px.
    rotation_range = 10, # Rota aleatoriamente las imágenes.
    width_shift_range = 0.15, # Mueve en el ancho hacia la izq. o derecha.
    height_shift_range = 0.15, # Mueve en el alto hacia arriba o abajo.
    shear_range = 5, # Para que las deforme un poco.
    zoom_range = [0.7, 1.3], # Lista con dos valores: Mínimo acercamiento y Máximo acercamiento.
    validation_split = 0.2, # Validación: el 20% de las imágenes serán utilizadas para las pruebas.
)

# Set de Datos de Entrenamiento
data_gen_entrenamiento = datagen.flow_from_directory('/content/dataset', # Ubicación del set de datos
                                                     target_size = (224,224), # Tamaño que queremos de las imag.
                                                     batch_size = 32, # Tamaño del lote.
                                                     shuffle = True, # Para mezclarlas constantemente
                                                     subset = 'training') # Entrenamiento -> 'training'
# Set de Datos de Prueba: toma un 20%
data_gen_pruebas = datagen.flow_from_directory('/content/dataset',
                                                     target_size = (224,224),
                                                     batch_size = 32,
                                                     shuffle = True,
                                                     subset = 'validation')

# Ver graficamente como quedaron transformadas las imágenes
import matplotlib.pyplot as plt

for imagenes , etiquetas in data_gen_entrenamiento:
  for i in range(10):
    plt.subplot(2,5,i+1) # (2filas,5columnas,i+1)
    plt.imshow(imagenes[i])
  break

plt.show() # Mostrar

# Vamos a la 'Transferencia de Aprendizaje'
import tensorflow as tf
import tensorflow_hub as hub # Sitio donde ya existen modelos de Machine Learning, ya entrenados.

url = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'
mobilenetv2 = hub.KerasLayer(url, input_shape=(224 ,224, 3)) # (url, forma en que espera las imgs.224x224 y 3 (RGB - Color))

# Importante!
# Congelar las capas
mobilenetv2.trinable = False # Que no se pueda entrenar, porque ya lo está, por eso, congelamos pesos y sesgos.

# Creamos Modelo
modelo = tf.keras.Sequential([
    mobilenetv2, # Variable de entrada
    tf.keras.layers.Dense(units=2 , activation='softmax') # 2 neuronas(units): rostros-hombre y rostros-mujeres
])

# Compliar Modelo
modelo.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Entrenar Modelo
EPOCAS = 50
entrenamiento = modelo.fit(
    data_gen_entrenamiento, epochs=EPOCAS, batch_size=32,
    validation_data = data_gen_pruebas
)

from PIL import Image
import cv2

def categorizar(ruta):
  img = Image.open(ruta) # Ubicación de la imagen
  img = img.convert('RGB') # Convertirla a RGB
  img = np.array(img).astype(float) / 255 # Convertirla en un array de numpy de tipo float y normalizarla 0 - 1

  img = cv2.resize(img,(224,224)) # Redimensionarla adaptándola a 224px x 224px, es el tamaño que espera el modelo
                                  # señalado anteriormente

  prediccion = modelo.predict(img.reshape(-1,224,224,3)) # Cambiar la estructura del arreglo
  return np.argmax(prediccion[0], axis=-1) # Va a retornar 0 o 1

img_prediccion = 'hombre.jpg'
prediccion = categorizar(img_prediccion)

if prediccion == 0:
  print('Es rostro de hombre')
else:
  print('Es un rosto de mujer')

img_prediccion = 'mujer.jpg'
prediccion = categorizar(img_prediccion)

if prediccion == 0:
  print('Es rostro de hombre')
else:
  print('Es un rosto de mujer')

img_prediccion = 'fatima_florez.png'
prediccion = categorizar(img_prediccion)

if prediccion == 0:
  print('Es rostro de hombre')
else:
  print('Es un rosto de mujer')